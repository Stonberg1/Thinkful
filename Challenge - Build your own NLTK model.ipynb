{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /Users/Isaac/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /anaconda3/lib/python3.6/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /anaconda3/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "    /anaconda3/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "!python -m spacy download en\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "blake_poems = gutenberg.raw('blake-poems.txt')\n",
    "whitman_leaves = gutenberg.raw('whitman-leaves.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "blake_poems = text_cleaner(blake_poems)\n",
    "whitman_leaves = text_cleaner(whitman_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SONGS OF INNOCENCE AND OF EXPERIENCE and THE BOOK of THEL SONGS OF INNOCENCE INTRODUCTION Piping down the valleys wild, Piping songs of pleasant glee, On a cloud I saw a child, And he laughing said to me: \"Pipe a song about a Lamb!\" So I piped with merry cheer. \"Piper, pipe that song again;\" So I piped: he wept to hear. \"Drop thy pipe, thy happy pipe; Sing thy songs of happy cheer:!\" So I sang the same again, While he wept with joy to hear. \"Piper, sit thee down and write In a book, that all may read.\" So he vanish\\'d from my sight; And I pluck\\'d a hollow reed, And I made a rural pen, And I stain\\'d the water clear, And I wrote my happy songs Every child may joy to hear. THE SHEPHERD How sweet is the Shepherd\\'s sweet lot! From the morn to the evening he stays; He shall follow his sheep all the day, And his tongue shall be filled with praise. For he hears the lambs\\' innocent call, And he hears the ewes\\' tender reply; He is watching while they are in peace, For they know when their Shepher'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blake_poems[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Come, said my soul, Such verses for my Body let us write, (for we are one,) That should I after return, Or, long, long hence, in other spheres, There to some group of mates the chants resuming, (Tallying Earth's soil, trees, winds, tumultuous waves,) Ever with pleas'd smile I may keep on, Ever and ever yet the verses owning as, first, I here and now Signing for Soul and Body, set to them my name, Walt Whitman } One's-Self I Sing One's-self I sing, a simple separate person, Yet utter the word Democratic, the word En-Masse. Of physiology from top to toe I sing, Not physiognomy alone nor brain alone is worthy for the Muse, I say the Form complete is worthier far, The Female equally with the Male I sing. Of Life immense in passion, pulse, and power, Cheerful, for freest action form'd under the laws divine, The Modern Man I sing. } As I Ponder'd in Silence As I ponder'd in silence, Returning upon my poems, considering, lingering long, A Phantom arose before me with distrustful aspect, Terri\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitman_leaves[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "blake_poems_doc = nlp(blake_poems)\n",
    "whitman_leaves_doc = nlp(whitman_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...</td>\n",
       "      <td>Blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(INTRODUCTION, Piping, down, the, valleys, wil...</td>\n",
       "      <td>Blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(So, I, piped, with, merry, cheer, ., \")</td>\n",
       "      <td>Blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Piper, ,, pipe, that, song, again)</td>\n",
       "      <td>Blake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(;, \", So, I, piped, :, he, wept, to, hear, ., \")</td>\n",
       "      <td>Blake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0      1\n",
       "0  (SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...  Blake\n",
       "1  (INTRODUCTION, Piping, down, the, valleys, wil...  Blake\n",
       "2           (So, I, piped, with, merry, cheer, ., \")  Blake\n",
       "3                (Piper, ,, pipe, that, song, again)  Blake\n",
       "4  (;, \", So, I, piped, :, he, wept, to, hear, ., \")  Blake"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "# Separatng Blake poem titles from poem text\n",
    "\n",
    "blake_lines = [[line, \"Blake\"] for line in blake_poems_doc.sents if not line.text.isupper()]\n",
    "blake_titles = [[title, \"Blake\"] for title in blake_poems_doc.sents if title.text.isupper()]\n",
    "whitman_sents = [[sent, \"Whitman\"] for sent in whitman_leaves_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(blake_lines + blake_titles + whitman_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463    (Why, a, tender, curb, upon, the, youthful, bu...\n",
       "464    (Why, a, little, curtain, of, flesh, on, the, ...\n",
       "465    (The, Virgin, started, from, her, seat, ,, &, ...\n",
       "466                                      (THE, SHEPHERD)\n",
       "467                                (THE, ECHOING, GREEN)\n",
       "468                           (THE, CHIMNEY, -, SWEEPER)\n",
       "469                                     (LAUGHING, SONG)\n",
       "470                                      (DIVINE, IMAGE)\n",
       "471                                              (NIGHT)\n",
       "472                                             (SPRING)\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][sentences[1] == 'Blake'][-35:-25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words. Augmented to exclude titles - \n",
    "# if not line.text.isupper()\n",
    "\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence'][::100]):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "blakewords = bag_of_words(blake_poems_doc)\n",
    "whitmanwords = bag_of_words(whitman_leaves_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(blakewords + whitmanwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n"
     ]
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sentiment column with TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "word_counts['text_sentence_sentiment_polarity'] = word_counts['text_sentence'].apply(str).apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "word_counts['text_sentence_sentiment_subjectivity'] = word_counts['text_sentence'].apply(str).apply(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['text_sentence_avg_word_length'] = word_counts['text_sentence'].apply(str).apply(lambda x: x.split())\n",
    "word_counts['text_sentence_avg_word_length'] = word_counts['text_sentence_avg_word_length'].apply(lambda words: sum(len(word) for word in words) / len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personality</th>\n",
       "      <th>poor</th>\n",
       "      <th>stony</th>\n",
       "      <th>sell</th>\n",
       "      <th>victory</th>\n",
       "      <th>door</th>\n",
       "      <th>delight</th>\n",
       "      <th>substance</th>\n",
       "      <th>ned</th>\n",
       "      <th>bar</th>\n",
       "      <th>...</th>\n",
       "      <th>flash</th>\n",
       "      <th>whatev</th>\n",
       "      <th>manacle</th>\n",
       "      <th>while</th>\n",
       "      <th>build</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>text_sentence_sentiment_polarity</th>\n",
       "      <th>text_sentence_sentiment_subjectivity</th>\n",
       "      <th>text_sentence_avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...</td>\n",
       "      <td>Blake</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(INTRODUCTION, Piping, down, the, valleys, wil...</td>\n",
       "      <td>Blake</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.551852</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, I, piped, with, merry, cheer, ., \")</td>\n",
       "      <td>Blake</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Piper, ,, pipe, that, song, again)</td>\n",
       "      <td>Blake</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(;, \", So, I, piped, :, he, wept, to, hear, ., \")</td>\n",
       "      <td>Blake</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  personality poor stony sell victory door delight substance ned bar  \\\n",
       "0           0    0     0    0       0    0       0         0   0   0   \n",
       "1           0    0     0    0       0    0       0         0   0   0   \n",
       "2           0    0     0    0       0    0       0         0   0   0   \n",
       "3           0    0     0    0       0    0       0         0   0   0   \n",
       "4           0    0     0    0       0    0       0         0   0   0   \n",
       "\n",
       "               ...              flash whatev manacle while build  \\\n",
       "0              ...                  0      0       0     0     0   \n",
       "1              ...                  0      0       0     0     0   \n",
       "2              ...                  0      0       0     0     0   \n",
       "3              ...                  0      0       0     0     0   \n",
       "4              ...                  0      0       0     0     0   \n",
       "\n",
       "                                       text_sentence text_source  \\\n",
       "0  (SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...       Blake   \n",
       "1  (INTRODUCTION, Piping, down, the, valleys, wil...       Blake   \n",
       "2           (So, I, piped, with, merry, cheer, ., \")       Blake   \n",
       "3                (Piper, ,, pipe, that, song, again)       Blake   \n",
       "4  (;, \", So, I, piped, :, he, wept, to, hear, ., \")       Blake   \n",
       "\n",
       "  text_sentence_sentiment_polarity text_sentence_sentiment_subjectivity  \\\n",
       "0                         0.000000                             0.000000   \n",
       "1                         0.287037                             0.551852   \n",
       "2                         0.000000                             0.000000   \n",
       "3                         0.000000                             0.000000   \n",
       "4                         0.000000                             0.000000   \n",
       "\n",
       "  text_sentence_avg_word_length  \n",
       "0                      4.500000  \n",
       "1                      4.200000  \n",
       "2                      3.428571  \n",
       "3                      4.600000  \n",
       "4                      2.777778  \n",
       "\n",
       "[5 rows x 2585 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personality</th>\n",
       "      <th>poor</th>\n",
       "      <th>stony</th>\n",
       "      <th>sell</th>\n",
       "      <th>victory</th>\n",
       "      <th>door</th>\n",
       "      <th>delight</th>\n",
       "      <th>substance</th>\n",
       "      <th>ned</th>\n",
       "      <th>bar</th>\n",
       "      <th>...</th>\n",
       "      <th>whatev</th>\n",
       "      <th>manacle</th>\n",
       "      <th>while</th>\n",
       "      <th>build</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>text_sentence_sentiment_polarity</th>\n",
       "      <th>text_sentence_sentiment_subjectivity</th>\n",
       "      <th>text_sentence_avg_word_length</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, Virgin, started, from, her, seat, ,, &amp;, ...</td>\n",
       "      <td>Blake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.095238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(THE, SHEPHERD)</td>\n",
       "      <td>Blake</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2586 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    personality poor stony sell victory door delight substance ned bar  ...    \\\n",
       "465           0    0     0    0       0    0       0         0   0   0  ...     \n",
       "466           0    0     0    0       0    0       0         0   0   0  ...     \n",
       "\n",
       "    whatev manacle while build  \\\n",
       "465      0       0     0     0   \n",
       "466      0       0     0     0   \n",
       "\n",
       "                                         text_sentence text_source  \\\n",
       "465  (The, Virgin, started, from, her, seat, ,, &, ...       Blake   \n",
       "466                                    (THE, SHEPHERD)       Blake   \n",
       "\n",
       "    text_sentence_sentiment_polarity text_sentence_sentiment_subjectivity  \\\n",
       "465                              0.0                                  0.0   \n",
       "466                              0.0                                  0.0   \n",
       "\n",
       "    text_sentence_avg_word_length titles  \n",
       "465                      4.095238      0  \n",
       "466                      5.500000      1  \n",
       "\n",
       "[2 rows x 2586 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a feature encoding titles for blake poems\n",
    "\n",
    "len_blake_lines = len(blake_lines)\n",
    "len_total_blake = len(blake_lines + blake_titles)\n",
    "\n",
    "word_counts['titles'] = 0\n",
    "word_counts['titles'].loc[len_blake_lines:len_total_blake] = 1\n",
    "\n",
    "word_counts.iloc[len_blake_lines-1:len_blake_lines+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personality</th>\n",
       "      <th>poor</th>\n",
       "      <th>stony</th>\n",
       "      <th>sell</th>\n",
       "      <th>victory</th>\n",
       "      <th>door</th>\n",
       "      <th>delight</th>\n",
       "      <th>substance</th>\n",
       "      <th>ned</th>\n",
       "      <th>bar</th>\n",
       "      <th>...</th>\n",
       "      <th>whatev</th>\n",
       "      <th>manacle</th>\n",
       "      <th>while</th>\n",
       "      <th>build</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>text_sentence_sentiment_polarity</th>\n",
       "      <th>text_sentence_sentiment_subjectivity</th>\n",
       "      <th>text_sentence_avg_word_length</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(INTRODUCTION, Piping, down, the, valleys, wil...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.551852</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, I, piped, with, merry, cheer, ., \")</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Piper, ,, pipe, that, song, again)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(;, \", So, I, piped, :, he, wept, to, hear, ., \")</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2586 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  personality poor stony sell victory door delight substance ned bar  ...    \\\n",
       "0           0    0     0    0       0    0       0         0   0   0  ...     \n",
       "1           0    0     0    0       0    0       0         0   0   0  ...     \n",
       "2           0    0     0    0       0    0       0         0   0   0  ...     \n",
       "3           0    0     0    0       0    0       0         0   0   0  ...     \n",
       "4           0    0     0    0       0    0       0         0   0   0  ...     \n",
       "\n",
       "  whatev manacle while build  \\\n",
       "0      0       0     0     0   \n",
       "1      0       0     0     0   \n",
       "2      0       0     0     0   \n",
       "3      0       0     0     0   \n",
       "4      0       0     0     0   \n",
       "\n",
       "                                       text_sentence text_source  \\\n",
       "0  (SONGS, OF, INNOCENCE, AND, OF, EXPERIENCE, an...           1   \n",
       "1  (INTRODUCTION, Piping, down, the, valleys, wil...           1   \n",
       "2           (So, I, piped, with, merry, cheer, ., \")           1   \n",
       "3                (Piper, ,, pipe, that, song, again)           1   \n",
       "4  (;, \", So, I, piped, :, he, wept, to, hear, ., \")           1   \n",
       "\n",
       "  text_sentence_sentiment_polarity text_sentence_sentiment_subjectivity  \\\n",
       "0                         0.000000                             0.000000   \n",
       "1                         0.287037                             0.551852   \n",
       "2                         0.000000                             0.000000   \n",
       "3                         0.000000                             0.000000   \n",
       "4                         0.000000                             0.000000   \n",
       "\n",
       "  text_sentence_avg_word_length titles  \n",
       "0                      4.500000      0  \n",
       "1                      4.200000      0  \n",
       "2                      3.428571      0  \n",
       "3                      4.600000      0  \n",
       "4                      2.777778      0  \n",
       "\n",
       "[5 rows x 2586 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding Blake\n",
    "word_counts.text_source = word_counts.text_source.eq('Blake').mul(1)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3724, 2584) (3724,)\n",
      "Training set score: 0.9264232008592911\n",
      "\n",
      "Test set score: 0.9335481272654047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2297    1]\n",
      " [ 164   21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      2298\n",
      "           1       0.95      0.11      0.20       185\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2483\n",
      "   macro avg       0.94      0.56      0.58      2483\n",
      "weighted avg       0.93      0.93      0.91      2483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3724, 2584) (3724,)\n",
      "Training set score: 0.9296455424274973\n",
      "\n",
      "Test set score: 0.93717277486911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "                intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "                multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "                verbose=0)\n",
    "\n",
    "# svm = SVC()\n",
    "train = svm.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', svm.score(X_train, y_train))\n",
    "print('\\nTest set score:', svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2297    1]\n",
      " [ 155   30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2298\n",
      "           1       0.97      0.16      0.28       185\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2483\n",
      "   macro avg       0.95      0.58      0.62      2483\n",
      "weighted avg       0.94      0.94      0.92      2483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9299140708915145\n",
      "\n",
      "Test set score: 0.9387837293596456\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2296    2]\n",
      " [ 150   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2298\n",
      "           1       0.95      0.19      0.32       185\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2483\n",
      "   macro avg       0.94      0.59      0.64      2483\n",
      "weighted avg       0.94      0.94      0.92      2483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the Gradient Boosting model worked the best. Unfortunately I am getting obviously low recall score and f1-score. A system with high precision but low recall is returning very few (positive) results, but most of its predicted labels are correct when compared to the training labels. Recall measures effectiveness of labelling true positives.\n",
    "\n",
    "The implication here is that there is a class imbalance (there are simply fewer words for Blake text). The evidence is below (5709 positives vs 498). But the model is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personality</th>\n",
       "      <th>poor</th>\n",
       "      <th>stony</th>\n",
       "      <th>sell</th>\n",
       "      <th>victory</th>\n",
       "      <th>door</th>\n",
       "      <th>delight</th>\n",
       "      <th>substance</th>\n",
       "      <th>ned</th>\n",
       "      <th>bar</th>\n",
       "      <th>...</th>\n",
       "      <th>flash</th>\n",
       "      <th>whatev</th>\n",
       "      <th>manacle</th>\n",
       "      <th>while</th>\n",
       "      <th>build</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_sentence_sentiment_polarity</th>\n",
       "      <th>text_sentence_sentiment_subjectivity</th>\n",
       "      <th>text_sentence_avg_word_length</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>...</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "      <td>5709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>...</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             personality  poor  stony  sell  victory  door  delight  \\\n",
       "text_source                                                           \n",
       "0                   5709  5709   5709  5709     5709  5709     5709   \n",
       "1                    498   498    498   498      498   498      498   \n",
       "\n",
       "             substance   ned   bar   ...    flash  whatev  manacle  while  \\\n",
       "text_source                          ...                                    \n",
       "0                 5709  5709  5709   ...     5709    5709     5709   5709   \n",
       "1                  498   498   498   ...      498     498      498    498   \n",
       "\n",
       "             build  text_sentence  text_sentence_sentiment_polarity  \\\n",
       "text_source                                                           \n",
       "0             5709           5709                              5709   \n",
       "1              498            498                               498   \n",
       "\n",
       "             text_sentence_sentiment_subjectivity  \\\n",
       "text_source                                         \n",
       "0                                            5709   \n",
       "1                                             498   \n",
       "\n",
       "             text_sentence_avg_word_length  titles  \n",
       "text_source                                         \n",
       "0                                     5709    5709  \n",
       "1                                      498     498  \n",
       "\n",
       "[2 rows x 2585 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.groupby('text_source').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
